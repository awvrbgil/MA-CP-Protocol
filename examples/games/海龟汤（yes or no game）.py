#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¢ æµ·é¾Ÿæ±¤æ¨ç†æ¸¸æˆ (Turtle Soup Game)
====================================
ä¸€ä¸ªåŸºäºAIçš„æµ·é¾Ÿæ±¤æ¨ç†æ¸¸æˆç‹¬ç«‹ç‰ˆæœ¬

è§„åˆ™ï¼š
1. ä¸¤ä¸ªAIä¼šè½®æµå‘æ‚¨æé—®
2. æ¯ä¸ªAIæ¯å›åˆåªèƒ½é—®ä¸€ä¸ªé—®é¢˜
3. æ‚¨åªèƒ½å›ç­” "æ˜¯"ã€"å¦" æˆ– "ä¸çŸ¥é“"
4. ç›®æ ‡æ˜¯è®©AIçŒœå‡ºè°œåº•

ä¾èµ–ï¼šPython 3.8+, requests, Ollama (æˆ–API)
"""

import os
import sys
import json
import time

# Windows ç»ˆç«¯ç¼–ç è®¾ç½®
if sys.platform == 'win32':
    try:
        import ctypes
        kernel32 = ctypes.windll.kernel32
        kernel32.SetConsoleOutputCP(65001)
        kernel32.SetConsoleCP(65001)
    except Exception:
        pass

# æ£€æŸ¥ requests ä¾èµ–
try:
    import requests
except ImportError:
    print("âŒ ç¼ºå°‘ä¾èµ–åº“ 'requests'ï¼Œæ­£åœ¨è‡ªåŠ¨å®‰è£…...")
    import subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "requests"])
    import requests


# ==================== ã€é…ç½®ã€‘ ====================
class Config:
    """æ¸¸æˆé…ç½®"""
    def __init__(self):
        self.ollama_url = "http://localhost:11434"
        self.model_1 = "qwen2.5:3b"           # AI1
        self.model_2 = "llama3.2:3b"          # AI2
        self.coordinator_model = "gemma3:4b"   # æ€»ç»“AI
        self.max_rounds = 10
        self.timeout = 60
        self.temperature = 0.7
        self.streaming_output = True
        
        # API é…ç½®ï¼ˆå¯é€‰ï¼‰
        self.use_api = False
        self.api_url = ""
        self.api_key = ""
        self.api_model = ""

config = Config()


# ==================== ã€Ollama å®¢æˆ·ç«¯ã€‘ ====================
class OllamaClient:
    """Ollama AI å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str = "http://localhost:11434"):
        self.base_url = base_url.rstrip('/')
        self.generate_url = f"{self.base_url}/api/generate"
        
    def generate_response(self, model: str, prompt: str, 
                         max_tokens: int = 500, temperature: float = 0.7,
                         streaming: bool = False) -> dict:
        """ç”Ÿæˆå“åº”"""
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": streaming,
            "options": {
                "temperature": temperature,
                "num_predict": max_tokens
            }
        }
        
        try:
            if streaming:
                return self._streaming_response(payload)
            else:
                response = requests.post(self.generate_url, json=payload, timeout=config.timeout)
                if response.status_code == 200:
                    result = response.json()
                    return {"success": True, "response": result.get("response", "")}
                return {"success": False, "response": f"é”™è¯¯: {response.status_code}"}
        except Exception as e:
            return {"success": False, "response": str(e)}
    
    def _streaming_response(self, payload: dict) -> dict:
        """æµå¼å“åº”"""
        full_response = ""
        try:
            response = requests.post(self.generate_url, json=payload, stream=True, timeout=config.timeout)
            for line in response.iter_lines():
                if line:
                    data = json.loads(line)
                    chunk = data.get("response", "")
                    print(chunk, end="", flush=True)
                    full_response += chunk
                    if data.get("done"):
                        break
            print()  # æ¢è¡Œ
            return {"success": True, "response": full_response}
        except Exception as e:
            return {"success": False, "response": str(e)}

    def list_models(self) -> list:
        """åˆ—å‡ºå¯ç”¨æ¨¡å‹"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=10)
            if response.status_code == 200:
                models = response.json().get("models", [])
                return [m.get("name", "") for m in models]
        except Exception:
            pass
        return []


# ==================== ã€API å®¢æˆ·ç«¯ã€‘ ====================
class APIClient:
    """é€šç”¨ API å®¢æˆ·ç«¯ï¼ˆOpenAIå…¼å®¹æ ¼å¼ï¼‰"""
    
    def __init__(self, api_url: str, api_key: str, model: str):
        self.api_url = api_url
        self.api_key = api_key
        self.model = model
        
    def generate_response(self, prompt: str, max_tokens: int = 500, 
                         temperature: float = 0.7) -> dict:
        """ç”Ÿæˆå“åº”"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": max_tokens,
            "temperature": temperature
        }
        
        try:
            response = requests.post(self.api_url, headers=headers, json=payload, timeout=config.timeout)
            if response.status_code == 200:
                result = response.json()
                content = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                return {"success": True, "response": content}
            return {"success": False, "response": f"APIé”™è¯¯: {response.status_code}"}
        except Exception as e:
            return {"success": False, "response": str(e)}


# ==================== ã€æ¸¸æˆæ ¸å¿ƒã€‘ ====================
class TurtleSoupGame:
    """æµ·é¾Ÿæ±¤æ¸¸æˆ"""
    
    def __init__(self):
        self.client = OllamaClient(config.ollama_url)
        self.api_client = None
        if config.use_api and config.api_url and config.api_key:
            self.api_client = APIClient(config.api_url, config.api_key, config.api_model)
    
    def _get_response(self, model: str, prompt: str, max_tokens: int = 500) -> dict:
        """è·å–AIå“åº”"""
        if config.use_api and self.api_client:
            return self.api_client.generate_response(prompt, max_tokens, config.temperature)
        return self.client.generate_response(model, prompt, max_tokens, 
                                            config.temperature, config.streaming_output)
    
    def play(self, riddle: str, role1: str = "ä¾¦æ¢", role2: str = "æ¨ç†è€…"):
        """å¼€å§‹æ¸¸æˆ"""
        print_header("ğŸ¢ æµ·é¾Ÿæ±¤æ¸¸æˆ (Turtle Soup Game)")
        print("æ¸¸æˆè§„åˆ™ (Rules):")
        print("1. ä¸¤ä¸ªAIä¼šè½®æµå‘æ‚¨æé—® (Two AIs take turns asking questions)")
        print("2. æ¯ä¸ªAIæ¯å›åˆåªèƒ½é—®ä¸€ä¸ªé—®é¢˜ (One question per turn)")
        print("3. æ‚¨åªèƒ½å›ç­” 'æ˜¯'ã€'å¦' æˆ– 'ä¸çŸ¥é“' (Answer: Yes/No/Unknown)")
        print("4. ç›®æ ‡æ˜¯è®©AIçŒœå‡ºè°œåº• (Goal: Let AI guess the answer)")
        print_separator()
        
        history = []
        round_count = 0
        
        while round_count < config.max_rounds:
            round_count += 1
            print_separator("-", 40)
            print(f"ç¬¬{round_count}å›åˆ (Round {round_count})")
            print_separator("-", 40)
            
            # äº¤æ›¿æé—®
            current_role = role1 if round_count % 2 == 1 else role2
            current_model = config.model_1 if round_count % 2 == 1 else config.model_2
            
            # ç”Ÿæˆé—®é¢˜
            if round_count == 1:
                prompt = f"""ä½ æ˜¯{current_role}ï¼Œæ­£åœ¨ç©æµ·é¾Ÿæ±¤æ¸¸æˆã€‚
è°œé¢ï¼š{riddle}
ä½ çš„ä»»åŠ¡æ˜¯å‘ç©å®¶æé—®ï¼Œæ¯æ¬¡åªèƒ½é—®ä¸€ä¸ªé—®é¢˜ï¼Œç©å®¶åªèƒ½å›ç­”æ˜¯ã€å¦æˆ–ä¸çŸ¥é“ã€‚
è¯·å¼€å§‹ä½ çš„ç¬¬ä¸€ä¸ªé—®é¢˜ï¼ˆåªé—®ä¸€ä¸ªé—®é¢˜ï¼‰ï¼š"""
            else:
                history_text = "\n".join(history[-4:])
                prompt = f"""ä½ æ˜¯{current_role}ï¼Œæ­£åœ¨ç©æµ·é¾Ÿæ±¤æ¸¸æˆã€‚
è°œé¢ï¼š{riddle}
å†å²é—®ç­”ï¼š
{history_text}
è¯·åŸºäºä»¥ä¸Šä¿¡æ¯é—®ä¸‹ä¸€ä¸ªé—®é¢˜ï¼ˆåªé—®ä¸€ä¸ªé—®é¢˜ï¼‰ï¼š"""
            
            print(f"\nğŸ¤– {current_role} æ­£åœ¨æ€è€ƒ...", end="", flush=True)
            if not config.streaming_output:
                print()
            
            result = self._get_response(current_model, prompt, 200)
            
            if result.get("success"):
                question_text = result.get("response", "").strip()
                if not config.streaming_output:
                    print(f"\nâ“ {current_role} æé—®ï¼š{question_text}")
                else:
                    print(f"â“ {current_role} æé—®å®Œæ¯•")
                
                # ç”¨æˆ·å›ç­”
                answer = self._get_answer()
                if answer == "ç»“æŸ":
                    print("ğŸ‘¤ æ‚¨é€‰æ‹©ç»“æŸæ¸¸æˆ (You chose to end)")
                    break
                
                history.append(f"é—®ï¼š{question_text}")
                history.append(f"ç­”ï¼š{answer}")
                
                # æ¯3å›åˆå°è¯•çŒœæµ‹
                if round_count % 3 == 0:
                    guess = self._attempt_guess(current_model, current_role, riddle, history)
                    if guess and self._confirm_guess():
                        print(f"\nğŸ‰ æ­å–œï¼{current_role} çŒœå¯¹äº†ï¼(Correct!)")
                        break
            else:
                print(f"âŒ {current_role} æé—®å¤±è´¥: {result.get('response', '')}")
                break
        
        # æœ€ç»ˆæ€»ç»“
        self._finalize(riddle, history)
    
    @staticmethod
    def _get_answer() -> str:
        """è·å–ç”¨æˆ·ç­”æ¡ˆ"""
        while True:
            answer = input("\næ‚¨çš„å›ç­” (Your answer) [æ˜¯/å¦/ä¸çŸ¥é“/ç»“æŸ] (Yes/No/Unknown/End): ").strip()
            # æ”¯æŒä¸­è‹±æ–‡è¾“å…¥
            answer_map = {
                "æ˜¯": "æ˜¯", "yes": "æ˜¯", "y": "æ˜¯",
                "å¦": "å¦", "no": "å¦", "n": "å¦",
                "ä¸çŸ¥é“": "ä¸çŸ¥é“", "unknown": "ä¸çŸ¥é“", "u": "ä¸çŸ¥é“", "idk": "ä¸çŸ¥é“",
                "ç»“æŸ": "ç»“æŸ", "end": "ç»“æŸ", "quit": "ç»“æŸ", "q": "ç»“æŸ"
            }
            normalized = answer_map.get(answer.lower())
            if normalized:
                return normalized
            print("âŒ è¯·å›ç­”ï¼šæ˜¯/å¦/ä¸çŸ¥é“/ç»“æŸ (Please answer: Yes/No/Unknown/End)")
    
    def _attempt_guess(self, model: str, role: str, riddle: str, history: list) -> str:
        """å°è¯•çŒœæµ‹ç­”æ¡ˆ"""
        guess_prompt = f"""åŸºäºä»¥ä¸‹ä¿¡æ¯ï¼Œè¯·çŒœæµ‹è°œåº•ï¼š
è°œé¢ï¼š{riddle}
å†å²é—®ç­”ï¼š
{chr(10).join(history[-6:])}
è¯·ç»™å‡ºä½ çš„çŒœæµ‹ï¼ˆå¦‚æœè¿˜ä¸ç¡®å®šå¯ä»¥è¯´'è¿˜éœ€è¦æ›´å¤šä¿¡æ¯'ï¼‰ï¼š"""
        
        print(f"\nğŸ¤” {role} æ­£åœ¨çŒœæµ‹...", end="", flush=True)
        if not config.streaming_output:
            print()
        
        result = self._get_response(model, guess_prompt, 300)
        
        if result.get("success"):
            guess = result.get("response", "").strip()
            if not config.streaming_output:
                print(f"\nğŸ’¡ {role} çŒœæµ‹ï¼š{guess}")
            else:
                print(f"ğŸ’¡ {role} çŒœæµ‹å®Œæ¯•")
            return guess
        return None
    
    @staticmethod
    def _confirm_guess() -> bool:
        """ç¡®è®¤çŒœæµ‹"""
        confirm = input("\nçŒœå¯¹äº†å—ï¼Ÿ(Correct?) [æ˜¯/å¦] (Yes/No): ").strip().lower()
        return confirm in ["æ˜¯", "yes", "y"]
    
    def _finalize(self, riddle: str, history: list):
        """æ¸¸æˆç»“æŸæ€»ç»“"""
        print_header("ğŸ“ æ¸¸æˆç»“æŸ (Game Over)")
        
        if history:
            final_prompt = f"""åŸºäºä»¥ä¸‹æµ·é¾Ÿæ±¤æ¸¸æˆè®°å½•ï¼Œè¯·æ€»ç»“ï¼š
è°œé¢ï¼š{riddle}
å†å²è®°å½•ï¼š
{chr(10).join(history)}
è¯·ç»™å‡ºæœ€ç»ˆåˆ†æå’Œè°œåº•è§£é‡Šï¼š"""
            
            print("\nğŸ¤– åè°ƒAIæ­£åœ¨æ€»ç»“...\n")
            result = self._get_response(config.coordinator_model, final_prompt, 500)
            
            if result.get("success"):
                summary = result.get("response", "")
                if not config.streaming_output:
                    print(f"ğŸ“‹ æœ€ç»ˆæ€»ç»“ (Final Summary)ï¼š")
                    print(summary)
        
        print("\n" + "=" * 60)
        print("æ„Ÿè°¢æ¸¸ç©ï¼(Thanks for playing!)")
        print("=" * 60)


# ==================== ã€è¾…åŠ©å‡½æ•°ã€‘ ====================
def print_separator(char: str = "=", length: int = 60):
    """æ‰“å°åˆ†éš”ç¬¦"""
    print(char * length)

def print_header(title: str):
    """æ‰“å°æ ‡é¢˜"""
    print_separator()
    print(f" {title} ".center(58))
    print_separator()


# ==================== ã€ä¸»ç¨‹åºã€‘ ====================
def main():
    """ä¸»å‡½æ•°"""
    print_header("ğŸ¢ æµ·é¾Ÿæ±¤æ¨ç†æ¸¸æˆ (Turtle Soup Game)")
    print("\næ¬¢è¿æ¥åˆ°æµ·é¾Ÿæ±¤æ¸¸æˆï¼(Welcome to Turtle Soup!)")
    print("è¿™æ˜¯ä¸€ä¸ªç”±AIè¾…åŠ©çš„æ¨ç†æ¸¸æˆã€‚\n")
    
    # æ£€æŸ¥ Ollama
    client = OllamaClient(config.ollama_url)
    models = client.list_models()
    
    if not models:
        print("âš ï¸ æœªæ£€æµ‹åˆ° Ollama æˆ–æ²¡æœ‰å¯ç”¨æ¨¡å‹")
        print("   (Ollama not detected or no models available)")
        print("\næ‚¨å¯ä»¥ï¼š")
        print("  1. å®‰è£…å¹¶å¯åŠ¨ Ollama: https://ollama.ai")
        print("  2. æˆ–é…ç½® API æ¨¡å¼ï¼ˆç¼–è¾‘æ­¤æ–‡ä»¶ä¸­çš„ configï¼‰")
        
        use_api = input("\næ˜¯å¦é…ç½® API æ¨¡å¼ï¼Ÿ(Configure API mode?) [y/N]: ").strip().lower()
        if use_api == 'y':
            config.use_api = True
            config.api_url = input("API URL (e.g., https://api.openai.com/v1/chat/completions): ").strip()
            config.api_key = input("API Key: ").strip()
            config.api_model = input("Model name (e.g., gpt-3.5-turbo): ").strip()
            config.streaming_output = False
        else:
            print("\nè¯·å…ˆå®‰è£… Ollama åå†è¿è¡Œæ¸¸æˆã€‚")
            return
    else:
        print(f"âœ… æ£€æµ‹åˆ° {len(models)} ä¸ªå¯ç”¨æ¨¡å‹ (Found {len(models)} models)")
        print(f"   å½“å‰ä½¿ç”¨ï¼š{config.model_1}, {config.model_2}")
    
    print_separator()
    
    while True:
        print("\nèœå• (Menu):")
        print("  1. å¼€å§‹æ–°æ¸¸æˆ (Start new game)")
        print("  2. é…ç½®è®¾ç½® (Settings)")
        print("  3. é€€å‡º (Exit)")
        
        choice = input("\né€‰æ‹©/Select: ").strip()
        
        if choice == "1":
            riddle = input("\nè¯·è¾“å…¥æµ·é¾Ÿæ±¤è°œé¢ (Enter riddle):\n>>> ").strip()
            if not riddle:
                print("âŒ è°œé¢ä¸èƒ½ä¸ºç©º (Riddle cannot be empty)")
                continue
            
            role1 = input("AI1è§’è‰² (AI1 role) [é»˜è®¤: ä¾¦æ¢]: ").strip() or "ä¾¦æ¢"
            role2 = input("AI2è§’è‰² (AI2 role) [é»˜è®¤: æ¨ç†è€…]: ").strip() or "æ¨ç†è€…"
            
            game = TurtleSoupGame()
            game.play(riddle, role1, role2)
            
        elif choice == "2":
            print("\nå½“å‰è®¾ç½® (Current Settings):")
            print(f"  - æ¨¡å‹1 (Model 1): {config.model_1}")
            print(f"  - æ¨¡å‹2 (Model 2): {config.model_2}")
            print(f"  - æ€»ç»“æ¨¡å‹ (Summary Model): {config.coordinator_model}")
            print(f"  - æœ€å¤§å›åˆ (Max Rounds): {config.max_rounds}")
            print(f"  - æµå¼è¾“å‡º (Streaming): {'æ˜¯/Yes' if config.streaming_output else 'å¦/No'}")
            
            change = input("\nä¿®æ”¹è®¾ç½®ï¼Ÿ(Change settings?) [y/N]: ").strip().lower()
            if change == 'y':
                config.model_1 = input(f"æ¨¡å‹1 [{config.model_1}]: ").strip() or config.model_1
                config.model_2 = input(f"æ¨¡å‹2 [{config.model_2}]: ").strip() or config.model_2
                config.max_rounds = int(input(f"æœ€å¤§å›åˆ [{config.max_rounds}]: ").strip() or config.max_rounds)
                print("âœ… è®¾ç½®å·²æ›´æ–° (Settings updated)")
                
        elif choice == "3":
            print("\nğŸ‘‹ å†è§ï¼(Goodbye!)")
            break
        else:
            print("âŒ æ— æ•ˆé€‰æ‹© (Invalid choice)")


if __name__ == "__main__":
    main()

